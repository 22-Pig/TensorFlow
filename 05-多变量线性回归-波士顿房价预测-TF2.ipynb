{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRIM: 城镇人均犯罪率                                                          AGE: 1940年之前建成的自用房屋比例\n",
    "\n",
    "ZN：住宅用地超过 25000 sq.ft. 的比例                             DIS：到波士顿5个中心区域的加权距离\n",
    "\n",
    "INDUS: 城镇非零售商用土地的比例                                    RAD: 辐射性公路的靠近指数\n",
    "\n",
    "CHAS: 边界是河流为1，否则0                                            TAX: 每10000美元的全值财产税率\n",
    "\n",
    "NOX: 一氧化氮浓度                                                               PTRATIO: 城镇师生比例         \n",
    "\n",
    "RM: 住宅平均房间数                                                             LSTAT: 人口中地位低下者的比例\n",
    "                                                                                                 MEDV: 自住房的平均房价，单位：千美元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过Pandas导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM         ZN       INDUS         CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
      "\n",
      "             MEDV  \n",
      "count  506.000000  \n",
      "mean    22.532806  \n",
      "std      9.197104  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n"
     ]
    }
   ],
   "source": [
    "# 读取数据文件\n",
    "\n",
    "df = pd.read_csv(\"data/boston.csv\", header=0)\n",
    "\n",
    "#显示数据摘要描述信息\n",
    "\n",
    "print (df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入本示例所需数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "# 获取df的值\n",
    "df = df.values\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对特征数据 【0到11】列 做（0-1）归一化\n",
    "for i in range(12):\n",
    "    df[:,i]=df[:,i]/(df[:,i].max()-df[:,i].min())\n",
    "    \n",
    "# x_data 为 归一化后的前12列特征数据\n",
    "x_data = df[:,:12] \n",
    "\n",
    "# y_data 为最后1列标签数据\n",
    "y_data = df[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape= (506, 12)\n",
      "y_data shape= (506,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_data shape=\", x_data.shape)\n",
    "print(\"y_data shape=\", y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_num = 300  # 训练集数目\n",
    "valid_num = 100  # 验证集数目\n",
    "test_num = len(x_data) - train_num - valid_num  # 测试集数目  506 - 训练集 - 验证集\n",
    "\n",
    "# 训练集划分 列表中的0-300的元素\n",
    "x_train = x_data[:train_num]\n",
    "y_train = y_data[:train_num]\n",
    "\n",
    "# 验证集划分 列表中的300-400的元素\n",
    "x_valid = x_data[train_num : train_num + valid_num]\n",
    "y_valid = y_data[train_num : train_num + valid_num]\n",
    "\n",
    "# 测试集划分 列表中的400 - 506的元素\n",
    "x_test = x_data[train_num + valid_num : train_num + valid_num + test_num]\n",
    "y_test = y_data[train_num + valid_num : train_num + valid_num + test_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "x_valid = tf.cast(x_valid, dtype=tf.float32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建待优化变量\n",
    "# random.normal([12,1] 生成数据 mean 是平均数，stddev 是标准差 生成了一个 12 行 1 列 的二维数组\n",
    "W = tf.Variable(tf.random.normal([12, 1], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "# zeros 函数生成 了一维的张量，里面的值是 0\n",
    "B = tf.Variable(tf.zeros(1), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "# 定义模型函数\n",
    "def model(x, w, b):\n",
    "    return tf.matmul(x, w) + b\n",
    "\n",
    "\n",
    "# 定义均方误差损失函数\n",
    "def loss(x, y, w, b):\n",
    "    err = model(x, w, b) - y\n",
    "    squared_err = tf.square(err)\n",
    "    return tf.reduce_mean(squared_err)\n",
    "\n",
    "\n",
    "# 定义梯度计算函数\n",
    "# 计算样本数据[x,y]在参数[w,b]点上的梯度\n",
    "\n",
    "\n",
    "def grad(x, y, w, b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x, y, w, b)\n",
    "    return tape.gradient(loss_, [w, b])  # 返回梯度向量\n",
    "\n",
    "\n",
    "# 定义模型的各种参数\n",
    "training_epochs = 500  # 迭代次数\n",
    "learning_rate = 0.001  # 学习率\n",
    "\n",
    "batch_size = 10  # 批量训练一次的样本数\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)  # 创建优化器，指定学习率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  1, train_loss=80.9320, valid_loss = 119.5794\n",
      "epoch=  2, train_loss=80.9737, valid_loss = 119.4602\n",
      "epoch=  3, train_loss=81.0161, valid_loss = 119.3434\n",
      "epoch=  4, train_loss=81.0591, valid_loss = 119.2288\n",
      "epoch=  5, train_loss=81.1027, valid_loss = 119.1165\n",
      "epoch=  6, train_loss=81.1468, valid_loss = 119.0064\n",
      "epoch=  7, train_loss=81.1914, valid_loss = 118.8985\n",
      "epoch=  8, train_loss=81.2366, valid_loss = 118.7927\n",
      "epoch=  9, train_loss=81.2822, valid_loss = 118.6889\n",
      "epoch= 10, train_loss=81.3283, valid_loss = 118.5872\n",
      "epoch= 11, train_loss=81.3749, valid_loss = 118.4875\n",
      "epoch= 12, train_loss=81.4219, valid_loss = 118.3897\n",
      "epoch= 13, train_loss=81.4693, valid_loss = 118.2938\n",
      "epoch= 14, train_loss=81.5171, valid_loss = 118.1998\n",
      "epoch= 15, train_loss=81.5653, valid_loss = 118.1075\n",
      "epoch= 16, train_loss=81.6138, valid_loss = 118.0170\n",
      "epoch= 17, train_loss=81.6627, valid_loss = 117.9283\n",
      "epoch= 18, train_loss=81.7119, valid_loss = 117.8413\n",
      "epoch= 19, train_loss=81.7615, valid_loss = 117.7559\n",
      "epoch= 20, train_loss=81.8113, valid_loss = 117.6722\n",
      "epoch= 21, train_loss=81.8614, valid_loss = 117.5901\n",
      "epoch= 22, train_loss=81.9118, valid_loss = 117.5095\n",
      "epoch= 23, train_loss=81.9625, valid_loss = 117.4304\n",
      "epoch= 24, train_loss=82.0134, valid_loss = 117.3529\n",
      "epoch= 25, train_loss=82.0645, valid_loss = 117.2768\n",
      "epoch= 26, train_loss=82.1158, valid_loss = 117.2022\n",
      "epoch= 27, train_loss=82.1673, valid_loss = 117.1289\n",
      "epoch= 28, train_loss=82.2191, valid_loss = 117.0571\n",
      "epoch= 29, train_loss=82.2710, valid_loss = 116.9865\n",
      "epoch= 30, train_loss=82.3231, valid_loss = 116.9173\n",
      "epoch= 31, train_loss=82.3753, valid_loss = 116.8493\n",
      "epoch= 32, train_loss=82.4277, valid_loss = 116.7827\n",
      "epoch= 33, train_loss=82.4802, valid_loss = 116.7172\n",
      "epoch= 34, train_loss=82.5328, valid_loss = 116.6529\n",
      "epoch= 35, train_loss=82.5856, valid_loss = 116.5899\n",
      "epoch= 36, train_loss=82.6385, valid_loss = 116.5280\n",
      "epoch= 37, train_loss=82.6914, valid_loss = 116.4672\n",
      "epoch= 38, train_loss=82.7445, valid_loss = 116.4075\n",
      "epoch= 39, train_loss=82.7976, valid_loss = 116.3489\n",
      "epoch= 40, train_loss=82.8508, valid_loss = 116.2914\n",
      "epoch= 41, train_loss=82.9041, valid_loss = 116.2349\n",
      "epoch= 42, train_loss=82.9574, valid_loss = 116.1795\n",
      "epoch= 43, train_loss=83.0108, valid_loss = 116.1250\n",
      "epoch= 44, train_loss=83.0642, valid_loss = 116.0715\n",
      "epoch= 45, train_loss=83.1176, valid_loss = 116.0189\n",
      "epoch= 46, train_loss=83.1711, valid_loss = 115.9673\n",
      "epoch= 47, train_loss=83.2246, valid_loss = 115.9166\n",
      "epoch= 48, train_loss=83.2781, valid_loss = 115.8669\n",
      "epoch= 49, train_loss=83.3316, valid_loss = 115.8179\n",
      "epoch= 50, train_loss=83.3851, valid_loss = 115.7699\n",
      "epoch= 51, train_loss=83.4386, valid_loss = 115.7227\n",
      "epoch= 52, train_loss=83.4921, valid_loss = 115.6763\n",
      "epoch= 53, train_loss=83.5456, valid_loss = 115.6307\n",
      "epoch= 54, train_loss=83.5991, valid_loss = 115.5859\n",
      "epoch= 55, train_loss=83.6525, valid_loss = 115.5419\n",
      "epoch= 56, train_loss=83.7059, valid_loss = 115.4986\n",
      "epoch= 57, train_loss=83.7592, valid_loss = 115.4562\n",
      "epoch= 58, train_loss=83.8125, valid_loss = 115.4143\n",
      "epoch= 59, train_loss=83.8658, valid_loss = 115.3733\n",
      "epoch= 60, train_loss=83.9190, valid_loss = 115.3329\n",
      "epoch= 61, train_loss=83.9721, valid_loss = 115.2932\n",
      "epoch= 62, train_loss=84.0252, valid_loss = 115.2542\n",
      "epoch= 63, train_loss=84.0782, valid_loss = 115.2158\n",
      "epoch= 64, train_loss=84.1312, valid_loss = 115.1780\n",
      "epoch= 65, train_loss=84.1841, valid_loss = 115.1409\n",
      "epoch= 66, train_loss=84.2369, valid_loss = 115.1044\n",
      "epoch= 67, train_loss=84.2896, valid_loss = 115.0685\n",
      "epoch= 68, train_loss=84.3422, valid_loss = 115.0333\n",
      "epoch= 69, train_loss=84.3948, valid_loss = 114.9986\n",
      "epoch= 70, train_loss=84.4473, valid_loss = 114.9644\n",
      "epoch= 71, train_loss=84.4996, valid_loss = 114.9308\n",
      "epoch= 72, train_loss=84.5519, valid_loss = 114.8978\n",
      "epoch= 73, train_loss=84.6041, valid_loss = 114.8652\n",
      "epoch= 74, train_loss=84.6561, valid_loss = 114.8333\n",
      "epoch= 75, train_loss=84.7081, valid_loss = 114.8018\n",
      "epoch= 76, train_loss=84.7600, valid_loss = 114.7708\n",
      "epoch= 77, train_loss=84.8117, valid_loss = 114.7403\n",
      "epoch= 78, train_loss=84.8634, valid_loss = 114.7103\n",
      "epoch= 79, train_loss=84.9149, valid_loss = 114.6808\n",
      "epoch= 80, train_loss=84.9663, valid_loss = 114.6518\n",
      "epoch= 81, train_loss=85.0176, valid_loss = 114.6231\n",
      "epoch= 82, train_loss=85.0688, valid_loss = 114.5950\n",
      "epoch= 83, train_loss=85.1198, valid_loss = 114.5673\n",
      "epoch= 84, train_loss=85.1707, valid_loss = 114.5399\n",
      "epoch= 85, train_loss=85.2215, valid_loss = 114.5130\n",
      "epoch= 86, train_loss=85.2722, valid_loss = 114.4865\n",
      "epoch= 87, train_loss=85.3227, valid_loss = 114.4604\n",
      "epoch= 88, train_loss=85.3732, valid_loss = 114.4348\n",
      "epoch= 89, train_loss=85.4234, valid_loss = 114.4095\n",
      "epoch= 90, train_loss=85.4736, valid_loss = 114.3845\n",
      "epoch= 91, train_loss=85.5236, valid_loss = 114.3600\n",
      "epoch= 92, train_loss=85.5734, valid_loss = 114.3358\n",
      "epoch= 93, train_loss=85.6232, valid_loss = 114.3120\n",
      "epoch= 94, train_loss=85.6728, valid_loss = 114.2885\n",
      "epoch= 95, train_loss=85.7222, valid_loss = 114.2654\n",
      "epoch= 96, train_loss=85.7715, valid_loss = 114.2426\n",
      "epoch= 97, train_loss=85.8207, valid_loss = 114.2201\n",
      "epoch= 98, train_loss=85.8697, valid_loss = 114.1979\n",
      "epoch= 99, train_loss=85.9186, valid_loss = 114.1761\n",
      "epoch=100, train_loss=85.9674, valid_loss = 114.1546\n",
      "epoch=101, train_loss=86.0160, valid_loss = 114.1333\n",
      "epoch=102, train_loss=86.0644, valid_loss = 114.1125\n",
      "epoch=103, train_loss=86.1127, valid_loss = 114.0918\n",
      "epoch=104, train_loss=86.1609, valid_loss = 114.0715\n",
      "epoch=105, train_loss=86.2089, valid_loss = 114.0514\n",
      "epoch=106, train_loss=86.2567, valid_loss = 114.0316\n",
      "epoch=107, train_loss=86.3044, valid_loss = 114.0121\n",
      "epoch=108, train_loss=86.3520, valid_loss = 113.9929\n",
      "epoch=109, train_loss=86.3994, valid_loss = 113.9739\n",
      "epoch=110, train_loss=86.4466, valid_loss = 113.9552\n",
      "epoch=111, train_loss=86.4937, valid_loss = 113.9367\n",
      "epoch=112, train_loss=86.5407, valid_loss = 113.9184\n",
      "epoch=113, train_loss=86.5875, valid_loss = 113.9004\n",
      "epoch=114, train_loss=86.6341, valid_loss = 113.8827\n",
      "epoch=115, train_loss=86.6806, valid_loss = 113.8651\n",
      "epoch=116, train_loss=86.7269, valid_loss = 113.8478\n",
      "epoch=117, train_loss=86.7731, valid_loss = 113.8307\n",
      "epoch=118, train_loss=86.8191, valid_loss = 113.8139\n",
      "epoch=119, train_loss=86.8650, valid_loss = 113.7972\n",
      "epoch=120, train_loss=86.9107, valid_loss = 113.7808\n",
      "epoch=121, train_loss=86.9563, valid_loss = 113.7646\n",
      "epoch=122, train_loss=87.0017, valid_loss = 113.7486\n",
      "epoch=123, train_loss=87.0470, valid_loss = 113.7327\n",
      "epoch=124, train_loss=87.0921, valid_loss = 113.7171\n",
      "epoch=125, train_loss=87.1370, valid_loss = 113.7017\n",
      "epoch=126, train_loss=87.1818, valid_loss = 113.6864\n",
      "epoch=127, train_loss=87.2265, valid_loss = 113.6713\n",
      "epoch=128, train_loss=87.2709, valid_loss = 113.6564\n",
      "epoch=129, train_loss=87.3153, valid_loss = 113.6418\n",
      "epoch=130, train_loss=87.3595, valid_loss = 113.6272\n",
      "epoch=131, train_loss=87.4035, valid_loss = 113.6128\n",
      "epoch=132, train_loss=87.4474, valid_loss = 113.5986\n",
      "epoch=133, train_loss=87.4911, valid_loss = 113.5846\n",
      "epoch=134, train_loss=87.5346, valid_loss = 113.5707\n",
      "epoch=135, train_loss=87.5781, valid_loss = 113.5571\n",
      "epoch=136, train_loss=87.6213, valid_loss = 113.5435\n",
      "epoch=137, train_loss=87.6644, valid_loss = 113.5301\n",
      "epoch=138, train_loss=87.7074, valid_loss = 113.5168\n",
      "epoch=139, train_loss=87.7502, valid_loss = 113.5037\n",
      "epoch=140, train_loss=87.7928, valid_loss = 113.4908\n",
      "epoch=141, train_loss=87.8353, valid_loss = 113.4780\n",
      "epoch=142, train_loss=87.8777, valid_loss = 113.4653\n",
      "epoch=143, train_loss=87.9199, valid_loss = 113.4528\n",
      "epoch=144, train_loss=87.9619, valid_loss = 113.4404\n",
      "epoch=145, train_loss=88.0038, valid_loss = 113.4281\n",
      "epoch=146, train_loss=88.0455, valid_loss = 113.4159\n",
      "epoch=147, train_loss=88.0871, valid_loss = 113.4039\n",
      "epoch=148, train_loss=88.1286, valid_loss = 113.3921\n",
      "epoch=149, train_loss=88.1699, valid_loss = 113.3803\n",
      "epoch=150, train_loss=88.2110, valid_loss = 113.3686\n",
      "epoch=151, train_loss=88.2520, valid_loss = 113.3571\n",
      "epoch=152, train_loss=88.2928, valid_loss = 113.3457\n",
      "epoch=153, train_loss=88.3335, valid_loss = 113.3344\n",
      "epoch=154, train_loss=88.3741, valid_loss = 113.3233\n",
      "epoch=155, train_loss=88.4145, valid_loss = 113.3122\n",
      "epoch=156, train_loss=88.4547, valid_loss = 113.3012\n",
      "epoch=157, train_loss=88.4948, valid_loss = 113.2904\n",
      "epoch=158, train_loss=88.5348, valid_loss = 113.2796\n",
      "epoch=159, train_loss=88.5746, valid_loss = 113.2690\n",
      "epoch=160, train_loss=88.6143, valid_loss = 113.2584\n",
      "epoch=161, train_loss=88.6538, valid_loss = 113.2480\n",
      "epoch=162, train_loss=88.6932, valid_loss = 113.2376\n",
      "epoch=163, train_loss=88.7324, valid_loss = 113.2274\n",
      "epoch=164, train_loss=88.7715, valid_loss = 113.2172\n",
      "epoch=165, train_loss=88.8105, valid_loss = 113.2072\n",
      "epoch=166, train_loss=88.8493, valid_loss = 113.1972\n",
      "epoch=167, train_loss=88.8880, valid_loss = 113.1873\n",
      "epoch=168, train_loss=88.9265, valid_loss = 113.1776\n",
      "epoch=169, train_loss=88.9649, valid_loss = 113.1679\n",
      "epoch=170, train_loss=89.0032, valid_loss = 113.1583\n",
      "epoch=171, train_loss=89.0413, valid_loss = 113.1487\n",
      "epoch=172, train_loss=89.0792, valid_loss = 113.1393\n",
      "epoch=173, train_loss=89.1171, valid_loss = 113.1299\n",
      "epoch=174, train_loss=89.1547, valid_loss = 113.1206\n",
      "epoch=175, train_loss=89.1923, valid_loss = 113.1114\n",
      "epoch=176, train_loss=89.2297, valid_loss = 113.1023\n",
      "epoch=177, train_loss=89.2670, valid_loss = 113.0933\n",
      "epoch=178, train_loss=89.3041, valid_loss = 113.0843\n",
      "epoch=179, train_loss=89.3411, valid_loss = 113.0753\n",
      "epoch=180, train_loss=89.3780, valid_loss = 113.0665\n",
      "epoch=181, train_loss=89.4147, valid_loss = 113.0577\n",
      "epoch=182, train_loss=89.4514, valid_loss = 113.0490\n",
      "epoch=183, train_loss=89.4878, valid_loss = 113.0404\n",
      "epoch=184, train_loss=89.5242, valid_loss = 113.0319\n",
      "epoch=185, train_loss=89.5604, valid_loss = 113.0234\n",
      "epoch=186, train_loss=89.5964, valid_loss = 113.0150\n",
      "epoch=187, train_loss=89.6324, valid_loss = 113.0066\n",
      "epoch=188, train_loss=89.6682, valid_loss = 112.9983\n",
      "epoch=189, train_loss=89.7038, valid_loss = 112.9901\n",
      "epoch=190, train_loss=89.7394, valid_loss = 112.9819\n",
      "epoch=191, train_loss=89.7748, valid_loss = 112.9738\n",
      "epoch=192, train_loss=89.8101, valid_loss = 112.9657\n",
      "epoch=193, train_loss=89.8452, valid_loss = 112.9578\n",
      "epoch=194, train_loss=89.8803, valid_loss = 112.9498\n",
      "epoch=195, train_loss=89.9152, valid_loss = 112.9419\n",
      "epoch=196, train_loss=89.9500, valid_loss = 112.9341\n",
      "epoch=197, train_loss=89.9846, valid_loss = 112.9264\n",
      "epoch=198, train_loss=90.0191, valid_loss = 112.9186\n",
      "epoch=199, train_loss=90.0535, valid_loss = 112.9109\n",
      "epoch=200, train_loss=90.0878, valid_loss = 112.9034\n",
      "epoch=201, train_loss=90.1219, valid_loss = 112.8958\n",
      "epoch=202, train_loss=90.1560, valid_loss = 112.8883\n",
      "epoch=203, train_loss=90.1898, valid_loss = 112.8808\n",
      "epoch=204, train_loss=90.2236, valid_loss = 112.8734\n",
      "epoch=205, train_loss=90.2573, valid_loss = 112.8661\n",
      "epoch=206, train_loss=90.2908, valid_loss = 112.8587\n",
      "epoch=207, train_loss=90.3242, valid_loss = 112.8515\n",
      "epoch=208, train_loss=90.3575, valid_loss = 112.8443\n",
      "epoch=209, train_loss=90.3907, valid_loss = 112.8372\n",
      "epoch=210, train_loss=90.4237, valid_loss = 112.8300\n",
      "epoch=211, train_loss=90.4566, valid_loss = 112.8230\n",
      "epoch=212, train_loss=90.4895, valid_loss = 112.8159\n",
      "epoch=213, train_loss=90.5221, valid_loss = 112.8089\n",
      "epoch=214, train_loss=90.5547, valid_loss = 112.8019\n",
      "epoch=215, train_loss=90.5872, valid_loss = 112.7950\n",
      "epoch=216, train_loss=90.6195, valid_loss = 112.7881\n",
      "epoch=217, train_loss=90.6517, valid_loss = 112.7813\n",
      "epoch=218, train_loss=90.6838, valid_loss = 112.7746\n",
      "epoch=219, train_loss=90.7158, valid_loss = 112.7678\n",
      "epoch=220, train_loss=90.7477, valid_loss = 112.7611\n",
      "epoch=221, train_loss=90.7795, valid_loss = 112.7544\n",
      "epoch=222, train_loss=90.8111, valid_loss = 112.7478\n",
      "epoch=223, train_loss=90.8426, valid_loss = 112.7412\n",
      "epoch=224, train_loss=90.8740, valid_loss = 112.7347\n",
      "epoch=225, train_loss=90.9054, valid_loss = 112.7281\n",
      "epoch=226, train_loss=90.9366, valid_loss = 112.7216\n",
      "epoch=227, train_loss=90.9676, valid_loss = 112.7152\n",
      "epoch=228, train_loss=90.9986, valid_loss = 112.7088\n",
      "epoch=229, train_loss=91.0295, valid_loss = 112.7024\n",
      "epoch=230, train_loss=91.0602, valid_loss = 112.6961\n",
      "epoch=231, train_loss=91.0909, valid_loss = 112.6898\n",
      "epoch=232, train_loss=91.1214, valid_loss = 112.6835\n",
      "epoch=233, train_loss=91.1518, valid_loss = 112.6772\n",
      "epoch=234, train_loss=91.1821, valid_loss = 112.6710\n",
      "epoch=235, train_loss=91.2123, valid_loss = 112.6648\n",
      "epoch=236, train_loss=91.2424, valid_loss = 112.6587\n",
      "epoch=237, train_loss=91.2724, valid_loss = 112.6525\n",
      "epoch=238, train_loss=91.3023, valid_loss = 112.6464\n",
      "epoch=239, train_loss=91.3321, valid_loss = 112.6404\n",
      "epoch=240, train_loss=91.3618, valid_loss = 112.6344\n",
      "epoch=241, train_loss=91.3913, valid_loss = 112.6283\n",
      "epoch=242, train_loss=91.4208, valid_loss = 112.6223\n",
      "epoch=243, train_loss=91.4502, valid_loss = 112.6164\n",
      "epoch=244, train_loss=91.4794, valid_loss = 112.6105\n",
      "epoch=245, train_loss=91.5086, valid_loss = 112.6046\n",
      "epoch=246, train_loss=91.5376, valid_loss = 112.5988\n",
      "epoch=247, train_loss=91.5666, valid_loss = 112.5929\n",
      "epoch=248, train_loss=91.5954, valid_loss = 112.5872\n",
      "epoch=249, train_loss=91.6242, valid_loss = 112.5814\n",
      "epoch=250, train_loss=91.6528, valid_loss = 112.5756\n",
      "epoch=251, train_loss=91.6813, valid_loss = 112.5699\n",
      "epoch=252, train_loss=91.7098, valid_loss = 112.5641\n",
      "epoch=253, train_loss=91.7381, valid_loss = 112.5584\n",
      "epoch=254, train_loss=91.7664, valid_loss = 112.5528\n",
      "epoch=255, train_loss=91.7945, valid_loss = 112.5472\n",
      "epoch=256, train_loss=91.8226, valid_loss = 112.5416\n",
      "epoch=257, train_loss=91.8505, valid_loss = 112.5360\n",
      "epoch=258, train_loss=91.8784, valid_loss = 112.5304\n",
      "epoch=259, train_loss=91.9061, valid_loss = 112.5249\n",
      "epoch=260, train_loss=91.9338, valid_loss = 112.5194\n",
      "epoch=261, train_loss=91.9613, valid_loss = 112.5139\n",
      "epoch=262, train_loss=91.9888, valid_loss = 112.5085\n",
      "epoch=263, train_loss=92.0162, valid_loss = 112.5030\n",
      "epoch=264, train_loss=92.0434, valid_loss = 112.4976\n",
      "epoch=265, train_loss=92.0706, valid_loss = 112.4922\n",
      "epoch=266, train_loss=92.0977, valid_loss = 112.4868\n",
      "epoch=267, train_loss=92.1247, valid_loss = 112.4814\n",
      "epoch=268, train_loss=92.1516, valid_loss = 112.4761\n",
      "epoch=269, train_loss=92.1784, valid_loss = 112.4707\n",
      "epoch=270, train_loss=92.2051, valid_loss = 112.4655\n",
      "epoch=271, train_loss=92.2317, valid_loss = 112.4602\n",
      "epoch=272, train_loss=92.2582, valid_loss = 112.4549\n",
      "epoch=273, train_loss=92.2847, valid_loss = 112.4497\n",
      "epoch=274, train_loss=92.3110, valid_loss = 112.4444\n",
      "epoch=275, train_loss=92.3373, valid_loss = 112.4392\n",
      "epoch=276, train_loss=92.3634, valid_loss = 112.4341\n",
      "epoch=277, train_loss=92.3895, valid_loss = 112.4289\n",
      "epoch=278, train_loss=92.4155, valid_loss = 112.4238\n",
      "epoch=279, train_loss=92.4414, valid_loss = 112.4186\n",
      "epoch=280, train_loss=92.4672, valid_loss = 112.4136\n",
      "epoch=281, train_loss=92.4929, valid_loss = 112.4084\n",
      "epoch=282, train_loss=92.5185, valid_loss = 112.4034\n",
      "epoch=283, train_loss=92.5440, valid_loss = 112.3983\n",
      "epoch=284, train_loss=92.5695, valid_loss = 112.3933\n",
      "epoch=285, train_loss=92.5949, valid_loss = 112.3883\n",
      "epoch=286, train_loss=92.6201, valid_loss = 112.3832\n",
      "epoch=287, train_loss=92.6453, valid_loss = 112.3782\n",
      "epoch=288, train_loss=92.6704, valid_loss = 112.3733\n",
      "epoch=289, train_loss=92.6955, valid_loss = 112.3683\n",
      "epoch=290, train_loss=92.7204, valid_loss = 112.3634\n",
      "epoch=291, train_loss=92.7452, valid_loss = 112.3585\n",
      "epoch=292, train_loss=92.7700, valid_loss = 112.3535\n",
      "epoch=293, train_loss=92.7947, valid_loss = 112.3487\n",
      "epoch=294, train_loss=92.8193, valid_loss = 112.3438\n",
      "epoch=295, train_loss=92.8438, valid_loss = 112.3389\n",
      "epoch=296, train_loss=92.8682, valid_loss = 112.3341\n",
      "epoch=297, train_loss=92.8926, valid_loss = 112.3292\n",
      "epoch=298, train_loss=92.9168, valid_loss = 112.3244\n",
      "epoch=299, train_loss=92.9410, valid_loss = 112.3197\n",
      "epoch=300, train_loss=92.9651, valid_loss = 112.3148\n",
      "epoch=301, train_loss=92.9891, valid_loss = 112.3101\n",
      "epoch=302, train_loss=93.0131, valid_loss = 112.3054\n",
      "epoch=303, train_loss=93.0369, valid_loss = 112.3006\n",
      "epoch=304, train_loss=93.0607, valid_loss = 112.2959\n",
      "epoch=305, train_loss=93.0844, valid_loss = 112.2912\n",
      "epoch=306, train_loss=93.1080, valid_loss = 112.2865\n",
      "epoch=307, train_loss=93.1315, valid_loss = 112.2818\n",
      "epoch=308, train_loss=93.1550, valid_loss = 112.2771\n",
      "epoch=309, train_loss=93.1784, valid_loss = 112.2725\n",
      "epoch=310, train_loss=93.2017, valid_loss = 112.2678\n",
      "epoch=311, train_loss=93.2249, valid_loss = 112.2632\n",
      "epoch=312, train_loss=93.2480, valid_loss = 112.2586\n",
      "epoch=313, train_loss=93.2711, valid_loss = 112.2539\n",
      "epoch=314, train_loss=93.2941, valid_loss = 112.2493\n",
      "epoch=315, train_loss=93.3170, valid_loss = 112.2448\n",
      "epoch=316, train_loss=93.3398, valid_loss = 112.2402\n",
      "epoch=317, train_loss=93.3626, valid_loss = 112.2356\n",
      "epoch=318, train_loss=93.3853, valid_loss = 112.2311\n",
      "epoch=319, train_loss=93.4079, valid_loss = 112.2265\n",
      "epoch=320, train_loss=93.4304, valid_loss = 112.2220\n",
      "epoch=321, train_loss=93.4529, valid_loss = 112.2175\n",
      "epoch=322, train_loss=93.4753, valid_loss = 112.2130\n",
      "epoch=323, train_loss=93.4976, valid_loss = 112.2085\n",
      "epoch=324, train_loss=93.5198, valid_loss = 112.2041\n",
      "epoch=325, train_loss=93.5420, valid_loss = 112.1996\n",
      "epoch=326, train_loss=93.5641, valid_loss = 112.1952\n",
      "epoch=327, train_loss=93.5861, valid_loss = 112.1907\n",
      "epoch=328, train_loss=93.6080, valid_loss = 112.1863\n",
      "epoch=329, train_loss=93.6299, valid_loss = 112.1819\n",
      "epoch=330, train_loss=93.6517, valid_loss = 112.1775\n",
      "epoch=331, train_loss=93.6734, valid_loss = 112.1731\n",
      "epoch=332, train_loss=93.6950, valid_loss = 112.1687\n",
      "epoch=333, train_loss=93.7166, valid_loss = 112.1643\n",
      "epoch=334, train_loss=93.7381, valid_loss = 112.1600\n",
      "epoch=335, train_loss=93.7596, valid_loss = 112.1556\n",
      "epoch=336, train_loss=93.7809, valid_loss = 112.1513\n",
      "epoch=337, train_loss=93.8022, valid_loss = 112.1469\n",
      "epoch=338, train_loss=93.8234, valid_loss = 112.1426\n",
      "epoch=339, train_loss=93.8446, valid_loss = 112.1383\n",
      "epoch=340, train_loss=93.8657, valid_loss = 112.1340\n",
      "epoch=341, train_loss=93.8867, valid_loss = 112.1297\n",
      "epoch=342, train_loss=93.9076, valid_loss = 112.1254\n",
      "epoch=343, train_loss=93.9285, valid_loss = 112.1212\n",
      "epoch=344, train_loss=93.9493, valid_loss = 112.1169\n",
      "epoch=345, train_loss=93.9701, valid_loss = 112.1126\n",
      "epoch=346, train_loss=93.9908, valid_loss = 112.1084\n",
      "epoch=347, train_loss=94.0114, valid_loss = 112.1041\n",
      "epoch=348, train_loss=94.0319, valid_loss = 112.0999\n",
      "epoch=349, train_loss=94.0524, valid_loss = 112.0957\n",
      "epoch=350, train_loss=94.0728, valid_loss = 112.0915\n",
      "epoch=351, train_loss=94.0931, valid_loss = 112.0873\n",
      "epoch=352, train_loss=94.1134, valid_loss = 112.0831\n",
      "epoch=353, train_loss=94.1336, valid_loss = 112.0789\n",
      "epoch=354, train_loss=94.1537, valid_loss = 112.0748\n",
      "epoch=355, train_loss=94.1738, valid_loss = 112.0706\n",
      "epoch=356, train_loss=94.1938, valid_loss = 112.0664\n",
      "epoch=357, train_loss=94.2137, valid_loss = 112.0623\n",
      "epoch=358, train_loss=94.2336, valid_loss = 112.0582\n",
      "epoch=359, train_loss=94.2534, valid_loss = 112.0541\n",
      "epoch=360, train_loss=94.2732, valid_loss = 112.0499\n",
      "epoch=361, train_loss=94.2928, valid_loss = 112.0458\n",
      "epoch=362, train_loss=94.3125, valid_loss = 112.0417\n",
      "epoch=363, train_loss=94.3320, valid_loss = 112.0377\n",
      "epoch=364, train_loss=94.3515, valid_loss = 112.0335\n",
      "epoch=365, train_loss=94.3709, valid_loss = 112.0295\n",
      "epoch=366, train_loss=94.3903, valid_loss = 112.0254\n",
      "epoch=367, train_loss=94.4096, valid_loss = 112.0213\n",
      "epoch=368, train_loss=94.4289, valid_loss = 112.0173\n",
      "epoch=369, train_loss=94.4480, valid_loss = 112.0133\n",
      "epoch=370, train_loss=94.4672, valid_loss = 112.0092\n",
      "epoch=371, train_loss=94.4862, valid_loss = 112.0051\n",
      "epoch=372, train_loss=94.5052, valid_loss = 112.0012\n",
      "epoch=373, train_loss=94.5241, valid_loss = 111.9971\n",
      "epoch=374, train_loss=94.5430, valid_loss = 111.9931\n",
      "epoch=375, train_loss=94.5618, valid_loss = 111.9892\n",
      "epoch=376, train_loss=94.5806, valid_loss = 111.9852\n",
      "epoch=377, train_loss=94.5992, valid_loss = 111.9812\n",
      "epoch=378, train_loss=94.6179, valid_loss = 111.9772\n",
      "epoch=379, train_loss=94.6364, valid_loss = 111.9733\n",
      "epoch=380, train_loss=94.6549, valid_loss = 111.9693\n",
      "epoch=381, train_loss=94.6734, valid_loss = 111.9653\n",
      "epoch=382, train_loss=94.6918, valid_loss = 111.9614\n",
      "epoch=383, train_loss=94.7101, valid_loss = 111.9575\n",
      "epoch=384, train_loss=94.7284, valid_loss = 111.9535\n",
      "epoch=385, train_loss=94.7466, valid_loss = 111.9496\n",
      "epoch=386, train_loss=94.7648, valid_loss = 111.9457\n",
      "epoch=387, train_loss=94.7828, valid_loss = 111.9418\n",
      "epoch=388, train_loss=94.8009, valid_loss = 111.9379\n",
      "epoch=389, train_loss=94.8189, valid_loss = 111.9340\n",
      "epoch=390, train_loss=94.8368, valid_loss = 111.9301\n",
      "epoch=391, train_loss=94.8547, valid_loss = 111.9262\n",
      "epoch=392, train_loss=94.8725, valid_loss = 111.9223\n",
      "epoch=393, train_loss=94.8902, valid_loss = 111.9185\n",
      "epoch=394, train_loss=94.9079, valid_loss = 111.9146\n",
      "epoch=395, train_loss=94.9256, valid_loss = 111.9108\n",
      "epoch=396, train_loss=94.9431, valid_loss = 111.9069\n",
      "epoch=397, train_loss=94.9607, valid_loss = 111.9031\n",
      "epoch=398, train_loss=94.9781, valid_loss = 111.8992\n",
      "epoch=399, train_loss=94.9956, valid_loss = 111.8954\n",
      "epoch=400, train_loss=95.0129, valid_loss = 111.8916\n",
      "epoch=401, train_loss=95.0302, valid_loss = 111.8878\n",
      "epoch=402, train_loss=95.0475, valid_loss = 111.8840\n",
      "epoch=403, train_loss=95.0647, valid_loss = 111.8802\n",
      "epoch=404, train_loss=95.0818, valid_loss = 111.8764\n",
      "epoch=405, train_loss=95.0989, valid_loss = 111.8726\n",
      "epoch=406, train_loss=95.1159, valid_loss = 111.8688\n",
      "epoch=407, train_loss=95.1329, valid_loss = 111.8650\n",
      "epoch=408, train_loss=95.1498, valid_loss = 111.8613\n",
      "epoch=409, train_loss=95.1667, valid_loss = 111.8575\n",
      "epoch=410, train_loss=95.1835, valid_loss = 111.8537\n",
      "epoch=411, train_loss=95.2003, valid_loss = 111.8500\n",
      "epoch=412, train_loss=95.2170, valid_loss = 111.8462\n",
      "epoch=413, train_loss=95.2336, valid_loss = 111.8425\n",
      "epoch=414, train_loss=95.2502, valid_loss = 111.8387\n",
      "epoch=415, train_loss=95.2668, valid_loss = 111.8350\n",
      "epoch=416, train_loss=95.2833, valid_loss = 111.8313\n",
      "epoch=417, train_loss=95.2997, valid_loss = 111.8276\n",
      "epoch=418, train_loss=95.3161, valid_loss = 111.8239\n",
      "epoch=419, train_loss=95.3325, valid_loss = 111.8201\n",
      "epoch=420, train_loss=95.3488, valid_loss = 111.8164\n",
      "epoch=421, train_loss=95.3650, valid_loss = 111.8128\n",
      "epoch=422, train_loss=95.3812, valid_loss = 111.8091\n",
      "epoch=423, train_loss=95.3973, valid_loss = 111.8054\n",
      "epoch=424, train_loss=95.4134, valid_loss = 111.8017\n",
      "epoch=425, train_loss=95.4294, valid_loss = 111.7980\n",
      "epoch=426, train_loss=95.4454, valid_loss = 111.7943\n",
      "epoch=427, train_loss=95.4614, valid_loss = 111.7906\n",
      "epoch=428, train_loss=95.4772, valid_loss = 111.7870\n",
      "epoch=429, train_loss=95.4931, valid_loss = 111.7833\n",
      "epoch=430, train_loss=95.5089, valid_loss = 111.7797\n",
      "epoch=431, train_loss=95.5246, valid_loss = 111.7760\n",
      "epoch=432, train_loss=95.5403, valid_loss = 111.7724\n",
      "epoch=433, train_loss=95.5559, valid_loss = 111.7688\n",
      "epoch=434, train_loss=95.5715, valid_loss = 111.7652\n",
      "epoch=435, train_loss=95.5870, valid_loss = 111.7616\n",
      "epoch=436, train_loss=95.6025, valid_loss = 111.7579\n",
      "epoch=437, train_loss=95.6180, valid_loss = 111.7543\n",
      "epoch=438, train_loss=95.6334, valid_loss = 111.7507\n",
      "epoch=439, train_loss=95.6487, valid_loss = 111.7471\n",
      "epoch=440, train_loss=95.6640, valid_loss = 111.7436\n",
      "epoch=441, train_loss=95.6793, valid_loss = 111.7399\n",
      "epoch=442, train_loss=95.6945, valid_loss = 111.7363\n",
      "epoch=443, train_loss=95.7096, valid_loss = 111.7327\n",
      "epoch=444, train_loss=95.7247, valid_loss = 111.7292\n",
      "epoch=445, train_loss=95.7398, valid_loss = 111.7256\n",
      "epoch=446, train_loss=95.7548, valid_loss = 111.7220\n",
      "epoch=447, train_loss=95.7697, valid_loss = 111.7185\n",
      "epoch=448, train_loss=95.7847, valid_loss = 111.7150\n",
      "epoch=449, train_loss=95.7996, valid_loss = 111.7113\n",
      "epoch=450, train_loss=95.8144, valid_loss = 111.7078\n",
      "epoch=451, train_loss=95.8291, valid_loss = 111.7042\n",
      "epoch=452, train_loss=95.8439, valid_loss = 111.7007\n",
      "epoch=453, train_loss=95.8586, valid_loss = 111.6972\n",
      "epoch=454, train_loss=95.8732, valid_loss = 111.6937\n",
      "epoch=455, train_loss=95.8878, valid_loss = 111.6902\n",
      "epoch=456, train_loss=95.9024, valid_loss = 111.6867\n",
      "epoch=457, train_loss=95.9169, valid_loss = 111.6832\n",
      "epoch=458, train_loss=95.9313, valid_loss = 111.6797\n",
      "epoch=459, train_loss=95.9458, valid_loss = 111.6762\n",
      "epoch=460, train_loss=95.9601, valid_loss = 111.6727\n",
      "epoch=461, train_loss=95.9745, valid_loss = 111.6692\n",
      "epoch=462, train_loss=95.9888, valid_loss = 111.6656\n",
      "epoch=463, train_loss=96.0030, valid_loss = 111.6622\n",
      "epoch=464, train_loss=96.0172, valid_loss = 111.6587\n",
      "epoch=465, train_loss=96.0313, valid_loss = 111.6552\n",
      "epoch=466, train_loss=96.0455, valid_loss = 111.6517\n",
      "epoch=467, train_loss=96.0595, valid_loss = 111.6483\n",
      "epoch=468, train_loss=96.0735, valid_loss = 111.6448\n",
      "epoch=469, train_loss=96.0875, valid_loss = 111.6413\n",
      "epoch=470, train_loss=96.1015, valid_loss = 111.6378\n",
      "epoch=471, train_loss=96.1154, valid_loss = 111.6345\n",
      "epoch=472, train_loss=96.1292, valid_loss = 111.6310\n",
      "epoch=473, train_loss=96.1430, valid_loss = 111.6275\n",
      "epoch=474, train_loss=96.1568, valid_loss = 111.6240\n",
      "epoch=475, train_loss=96.1705, valid_loss = 111.6206\n",
      "epoch=476, train_loss=96.1842, valid_loss = 111.6172\n",
      "epoch=477, train_loss=96.1978, valid_loss = 111.6138\n",
      "epoch=478, train_loss=96.2114, valid_loss = 111.6104\n",
      "epoch=479, train_loss=96.2249, valid_loss = 111.6069\n",
      "epoch=480, train_loss=96.2384, valid_loss = 111.6034\n",
      "epoch=481, train_loss=96.2519, valid_loss = 111.6001\n",
      "epoch=482, train_loss=96.2653, valid_loss = 111.5967\n",
      "epoch=483, train_loss=96.2787, valid_loss = 111.5933\n",
      "epoch=484, train_loss=96.2921, valid_loss = 111.5899\n",
      "epoch=485, train_loss=96.3054, valid_loss = 111.5865\n",
      "epoch=486, train_loss=96.3187, valid_loss = 111.5832\n",
      "epoch=487, train_loss=96.3319, valid_loss = 111.5797\n",
      "epoch=488, train_loss=96.3450, valid_loss = 111.5763\n",
      "epoch=489, train_loss=96.3582, valid_loss = 111.5730\n",
      "epoch=490, train_loss=96.3713, valid_loss = 111.5696\n",
      "epoch=491, train_loss=96.3844, valid_loss = 111.5662\n",
      "epoch=492, train_loss=96.3974, valid_loss = 111.5628\n",
      "epoch=493, train_loss=96.4104, valid_loss = 111.5595\n",
      "epoch=494, train_loss=96.4233, valid_loss = 111.5561\n",
      "epoch=495, train_loss=96.4362, valid_loss = 111.5527\n",
      "epoch=496, train_loss=96.4491, valid_loss = 111.5494\n",
      "epoch=497, train_loss=96.4619, valid_loss = 111.5461\n",
      "epoch=498, train_loss=96.4747, valid_loss = 111.5426\n",
      "epoch=499, train_loss=96.4874, valid_loss = 111.5393\n",
      "epoch=500, train_loss=96.5001, valid_loss = 111.5360\n"
     ]
    }
   ],
   "source": [
    "loss_list_train = []  # 用于保存训练集loss值的列表\n",
    "loss_list_valid = []  # 用于保存验证集loss值的列表\n",
    "total_step = int(train_num / batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = x_train[step * batch_size : (step + 1) * batch_size, :]\n",
    "        # 对x_train（300*12）依次存入第0-10，10-20行......数据\n",
    "\n",
    "        ys = y_train[step * batch_size : (step + 1) * batch_size]  #  对y_train（300*1）\n",
    "\n",
    "        grads = grad(xs, ys, W, B)  # 计算梯度\n",
    "        optimizer.apply_gradients(zip(grads, [W, B]))  # 优化器根据梯度自动调整变量 W和B\n",
    "\n",
    "    loss_train = loss(x_train, y_train, W, B).numpy()  # 计算当前轮训练损失\n",
    "    loss_valid = loss(x_valid, y_valid, W, B).numpy()  # 计算当前轮验证损失\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "\n",
    "    print(\n",
    "        \"epoch={:3d}, train_loss={:.4f}, valid_loss = {:.4f}\".format(\n",
    "            epoch + 1, loss_train, loss_valid\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化训练过程中的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x245845fbf70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_list_train, \"blue\", label=\"Train Loss\")\n",
    "plt.plot(loss_list_valid, \"red\", label=\"Valid Loss\")\n",
    "plt.legend(loc=1)  # 通过参数loc指定图例位置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss:80.6697\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_loss:{:.4f}\".format(loss(x_test, y_test, W, B).numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House id: 69 \n",
      "Actual value: 20.1 \n",
      "Predicted value: 21.650038\n"
     ]
    }
   ],
   "source": [
    "test_house_id = np.random.randint(0, test_num)\n",
    "y = y_test[test_house_id]\n",
    "y_pred = model(x_test, W, B)[test_house_id]\n",
    "y_predict = tf.reshape(y_pred, ()).numpy()\n",
    "print(\"House id:\", test_house_id, \"\\nActual value:\", y, \"\\nPredicted value:\", y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
